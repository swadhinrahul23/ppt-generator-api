---
description: 
globs: 
alwaysApply: false
---
# Agentforce Config Evaluator

## Overview
This rule set analyzes Agentforce configuration files to identify patterns and anti-patterns that might confuse the Atlas Reasoning Engine (powered by GPT-4o). Use these rules to validate your configuration markdown files such as agent specifications.

## Agent Definition Rules

### Good Patterns

1. **Clear Agent Name [REQUIRED]**
   - Agent names should be concise, descriptive, and follow PascalCase convention
   - Example: `SalesforceOpportunityAgent`

2. **Comprehensive Agent Description [REQUIRED]**
   - Agent descriptions should clearly state the agent's purpose in 1-2 sentences
   - Should outline core capabilities and domains of expertise
   - Example: `An AI assistant that creates Opportunities in Salesforce by capturing essential details...`

3. **Specific Agent Role Definition [REQUIRED]**
   - Agent role should precisely define the agent's persona and responsibilities
   - Should establish boundaries of capabilities and authority
   - Example: `You are a specialized assistant that helps consulting firm leaders create Salesforce Opportunities...`

4. **Detailed Company Context [REQUIRED]**
   - Company description should provide sufficient domain context for the Atlas Reasoning Engine
   - Should include industry, business model, and relevant terminology
   - Example: `A large consulting firm that manages client opportunities through Salesforce...`

### Anti-Patterns

1. **Vague Agent Name [HIGH]**
   - Avoid generic names that don't indicate the agent's purpose
   - Poor example: `SalesAgent` or `Assistant`

2. **Conflicting Role Definitions [HIGH]**
   - Avoid contradictory statements about what the agent can or should do
   - Poor example: `You are a data analyst who helps with marketing campaigns` (mixed roles)

3. **Overly Broad Capabilities [MEDIUM]**
   - Avoid suggesting the agent can handle any task without limitations
   - Poor example: `You can help with any Salesforce task across all clouds`

4. **Missing Company Context [MEDIUM]**
   - Lacking industry-specific terminology causes the LLM to make assumptions
   - Poor example: `A company that uses Salesforce`

## Topic Definition Rules

### Good Patterns

1. **Clearly Scoped Topics [REQUIRED]**
   - Each topic should have a focused scope with clear boundaries
   - Topics should be distinct from each other with minimal overlap
   - Example: `Opportunity Creation` vs. `Opportunity Status Inquiry`

2. **Descriptive Classification [REQUIRED]**
   - Topic classification descriptions should clearly distinguish the intent
   - Should establish when this topic applies vs. other topics
   - Example: `Handles the creation of new Opportunities in Salesforce by gathering required information...`

3. **Sequential, Specific Instructions [REQUIRED]**
   - Instructions should follow a logical sequence of steps
   - Should include specific action references with clear inputs/outputs
   - Example: `Verify the Account Name exists in Salesforce by using the "VerifyAccountExists" action.`

4. **Error Handling Instructions [RECOMMENDED]**
   - Include how to handle common errors or edge cases
   - Example: `If the account doesn't exist or has multiple potential matches, present the user with suggestions...`

### Anti-Patterns

1. **Ambiguous Topic Boundaries [HIGH]**
   - Topics with unclear boundaries confuse the reasoning engine
   - Poor example: Having both `Account Management` and `Account Updates` without clear distinction

2. **Inconsistent Terminology [HIGH]**
   - Using different terms for the same concept across topics
   - Poor example: Using both `Opportunity` and `Deal` interchangeably

3. **Circular References [MEDIUM]**
   - Instructions that reference other topics without clear resolution paths
   - Poor example: Topic A says "see Topic B" and Topic B says "see Topic A"

4. **Missing Decision Criteria [MEDIUM]**
   - Not providing clear guidance on how to choose between similar actions
   - Poor example: Listing multiple search actions without explaining when to use each

## Action Definition Rules

### Good Patterns

1. **Specific Action Type [REQUIRED]**
   - Clearly specify whether an action is Apex, Flow, or another type
   - Example: `Action Type: Apex`

2. **Comprehensive Action Instructions [REQUIRED]**
   - Provide detailed explanation of what the action does and when to use it
   - Include context about the system it interacts with
   - Example: `Verifies if an Account exists in Salesforce by searching for matches to the provided account name.`

3. **Complete Input/Output Definitions [REQUIRED]**
   - Clearly document all required and optional inputs with data types
   - Document all possible outputs, including error states
   - Example: `Inputs: accountName (Required): The name of the Account to verify.`

4. **Relationship Context [RECOMMENDED]**
   - Explain how this action relates to other actions in a workflow
   - Example: `This action should be called before CreateOpportunity to ensure valid account selection.`

### Anti-Patterns

1. **Undefined Action Types [HIGH]**
   - Not specifying whether an action is Apex, Flow, REST, etc.
   - Poor example: `Action Type: Custom`

2. **Inconsistent Parameter Naming [HIGH]**
   - Using different parameter names across similar actions
   - Poor example: `accountName` in one action and `acctName` in another

3. **Missing Required Input Definitions [HIGH]**
   - Not clearly marking which inputs are required vs. optional
   - Poor example: `Inputs: accountName: The name of the Account.` (required status unclear)

4. **Incomplete Output Descriptions [MEDIUM]**
   - Not documenting all possible output scenarios, especially errors
   - Poor example: Only describing the success case, not how errors are returned

## LLM Interaction Guidelines

### Good Patterns

1. **Explicit Reasoning Guidance [RECOMMENDED]**
   - Provide explicit guidance for multi-step reasoning
   - Example: `First determine the account type, then select the appropriate verification method based on type.`

2. **Clear Decision Trees [RECOMMENDED]**
   - Document decision points with clear criteria for each branch
   - Example: `If account exists, proceed to step 2. If not, offer to create a new account or search again.`

3. **Scenario-Based Examples [RECOMMENDED]**
   - Include representative examples of expected inputs and outputs
   - Example: `For input "Acme Corp", expected output may include Account ID and verification status.`

### Anti-Patterns

1. **Implicit Reasoning Requirements [HIGH]**
   - Assuming the LLM will infer complex decision logic without guidance
   - Poor example: `Choose the appropriate action based on the situation`

2. **Contradictory Instructions [HIGH]**
   - Providing conflicting guidance within the same topic or across topics
   - Poor example: `Always check permissions first` in one section and `Prioritize speed over permission checks` in another

3. **Ambiguous Prioritization [MEDIUM]**
   - Not clarifying which goals take precedence when conflicts arise
   - Poor example: `Ensure both speed and thoroughness` without explaining tradeoffs

## Validation Methods

1. **Configuration File Schema Validation**
   - Verify all required sections exist (Agent Name, Description, Role, Topics, Actions)
   - Check for consistent formatting and structure

2. **Cross-Reference Validation**
   - Ensure all referenced actions in instructions actually exist in Actions section
   - Verify topic boundaries are clear and non-overlapping

3. **Clarity and Specificity Check**
   - Review instructions for ambiguous or vague directives
   - Ensure all specialized terminology is defined or explained

4. **Simulated Query Testing**
   - Run sample queries against configuration to identify potential confusion points
   - Test edge cases and ambiguous requests to evaluate response quality


